{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/learning/mlops/pacmann/lazada-id-reviews/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the main directory\n",
    "# So, it's executed from main directory\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.env') as f:\n",
    "    os.environ.update(\n",
    "        line.strip().split('=') for line in f\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/learning/mlops/pacmann/lazada-id-reviews'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Testing Config\n",
    "\n",
    "This code will be apply in `src/LadazaIDReview/entity/config_entity.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class UnitTestConfig:\n",
    "    root_dir: Path\n",
    "    mlflow_tracking_uri: str\n",
    "    mlflow_model_name: str\n",
    "    mlflow_deploy_model_alias: str\n",
    "    mlflow_input_example_path: Path\n",
    "    app_endpoint: str\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Testing Config Manager\n",
    "\n",
    "This code will be apply in `src/LazadaIDReview/config/configurations.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LazadaIDReviews.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from LazadaIDReviews.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_filepath = CONFIG_FILE_PATH,\n",
    "                 params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_unit_test_config(self) -> UnitTestConfig:\n",
    "        \"\"\"read training evaluation config file and store as \n",
    "        config entity then apply the dataclasses\n",
    "        \n",
    "        Returns:\n",
    "            config: UnitTestConfig type\n",
    "        \"\"\"\n",
    "        predict_config = self.config.predict\n",
    "        unit_test_config = self.config.unit_test\n",
    "\n",
    "        create_directories([unit_test_config.root_dir])\n",
    "\n",
    "        config = UnitTestConfig(\n",
    "            root_dir=unit_test_config.root_dir,\n",
    "            mlflow_tracking_uri=os.environ[\"MLFLOW_TRACKING_URI\"],\n",
    "            mlflow_model_name=predict_config.mlflow_model_name,\n",
    "            mlflow_deploy_model_alias=os.environ[\"MLFLOW_DEPLOY_MODEL_ALIAS\"],\n",
    "            mlflow_input_example_path=unit_test_config.mlflow_input_example_path,\n",
    "            app_endpoint=os.environ[\"APP_ENDPOINT\"]\n",
    "        )\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.artifacts import download_artifacts\n",
    "from mlflow import MlflowClient\n",
    "from mlflow import pyfunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Debug**: Explain when doing the preparation test in the notebook with MLflow like load input example and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-11 08:31:38,789: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-09-11 08:31:38,792: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2024-09-11 08:31:38,792: INFO: common: created directory at: artifacts]\n",
      "[2024-09-11 08:31:38,794: INFO: common: created directory at: artifacts/test]\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "unit_test_config = config.get_unit_test_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the deployed model from MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlflow-artifacts:/1/1f046f7844764a9a907682ce09cca37e/artifacts/models'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MlflowClient(tracking_uri=unit_test_config.mlflow_tracking_uri)\n",
    "selected_model = client.get_model_version_by_alias(\n",
    "    unit_test_config.mlflow_model_name, \n",
    "    unit_test_config.mlflow_deploy_model_alias\n",
    ")\n",
    "\n",
    "selected_model.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/learning/mlops/pacmann/lazada-id-reviews/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 870.28it/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: models\n",
       "  flavor: mlflow.sklearn\n",
       "  run_id: 1f046f7844764a9a907682ce09cca37e"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = pyfunc.load_model(model_uri=selected_model.source)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the model `run_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1f046f7844764a9a907682ce09cca37e'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_run_id = selected_model.run_id\n",
    "selected_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 85.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/learning/mlops/pacmann/lazada-id-reviews/artifacts/test/models/input_example.json'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_artifacts(\n",
    "    run_id=selected_run_id,\n",
    "    artifact_path=unit_test_config.mlflow_input_example_path,\n",
    "    dst_path=unit_test_config.root_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': ['reviewContents'],\n",
       " 'data': [['brg mulus,kiriman jg cepat, thx'],\n",
       "  ['Terima kasih Adata Store dan Lazada, barang sudah sampai, mantab'],\n",
       "  ['Trimaksih Lazada barang nya sangat bagus dan memuas kan ..  Waktu pesen kemarin blm ada free besi ny .  Skrng udh ada .  Heee heee ..'],\n",
       "  ['barang sampai juga agak lama pengirimanya,, Alhamdulillah barang gak ada yg cacat,,'],\n",
       "  ['bagus, dapet bonus kabel strap lumayan ðŸ˜'],\n",
       "  ['Mohon tulis harga dengan benar'],\n",
       "  ['mantab jiwa,,sory barang ga sempat dipoto'],\n",
       "  ['Recomended banget lur...'],\n",
       "  ['Terima kasih Lazada pengiriman cepat dan packingnya rapi, barang sesuai dgn pesanan saya...tp belum saya coba aktifkan'],\n",
       "  ['Saya kira karena liburan bakal lama sampainya, ternyata tidak,  Barang asli setelah dibuka,sama dengan foto   Thanks lazada, memang effortless banget']]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "f = open(f\"{unit_test_config.root_dir}/{unit_test_config.mlflow_input_example_path}\")\n",
    "input_example = json.load(f)\n",
    "input_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the input data from MLflow input examples and try to match with the MLflow input example format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reviewContents': ['brg mulus,kiriman jg cepat, thx',\n",
       "  'Terima kasih Adata Store dan Lazada, barang sudah sampai, mantab',\n",
       "  'Trimaksih Lazada barang nya sangat bagus dan memuas kan ..  Waktu pesen kemarin blm ada free besi ny .  Skrng udh ada .  Heee heee ..',\n",
       "  'barang sampai juga agak lama pengirimanya,, Alhamdulillah barang gak ada yg cacat,,',\n",
       "  'bagus, dapet bonus kabel strap lumayan ðŸ˜',\n",
       "  'Mohon tulis harga dengan benar',\n",
       "  'mantab jiwa,,sory barang ga sempat dipoto',\n",
       "  'Recomended banget lur...',\n",
       "  'Terima kasih Lazada pengiriman cepat dan packingnya rapi, barang sesuai dgn pesanan saya...tp belum saya coba aktifkan',\n",
       "  'Saya kira karena liburan bakal lama sampainya, ternyata tidak,  Barang asli setelah dibuka,sama dengan foto   Thanks lazada, memang effortless banget']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_body = {\n",
    "    input_example[\"columns\"][0]: [i[0] for i in input_example['data']]\n",
    "}\n",
    "\n",
    "request_body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the `app.py` with http request with MLflow input data example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "result = requests.post(url=unit_test_config.app_endpoint, json=request_body)\n",
    "y_predict = result.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 5, 4, 3, 1, 5, 5, 5, 3]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Unit Testing\n",
    "\n",
    "This code in `src/LazadaIDReview/components/unit_testing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "from LazadaIDReviews import logger\n",
    "\n",
    "class UnitTesting:\n",
    "    def __init__(self, config: UnitTestConfig):\n",
    "        self.config = config\n",
    "        self.req_body_key = None\n",
    "        self.req_body = None\n",
    "    \n",
    "    def set_request_body(self) -> None:\n",
    "        \"\"\"predict the data with linear regression model\n",
    "\n",
    "        Raises:\n",
    "            client_error: error when access mlflow to get deployed model\n",
    "            download_error: error when download vectorizer from mlflow artifact\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Set MLflow Client.\")\n",
    "            client = MlflowClient(tracking_uri=self.config.mlflow_tracking_uri)\n",
    "            selected_model = client.get_model_version_by_alias(\n",
    "                self.config.mlflow_model_name, \n",
    "                self.config.mlflow_deploy_model_alias\n",
    "            )\n",
    "            \n",
    "            logger.info(\"Get the deployed model run id.\")\n",
    "            selected_run_id = selected_model.run_id\n",
    "        except Exception as client_error:\n",
    "            logger.error(client_error)\n",
    "            raise client_error\n",
    "\n",
    "        try:\n",
    "            logger.info(\"Downloading vectorizer from MLflow's artifacts.\")\n",
    "            download_artifacts(\n",
    "                run_id=selected_run_id,\n",
    "                artifact_path = self.config.mlflow_input_example_path,\n",
    "                dst_path = self.config.root_dir\n",
    "            )\n",
    "        except Exception as download_error:\n",
    "            logger.error(download_error)\n",
    "            raise download_error\n",
    "        \n",
    "        logger.info(\"Open MLflow input example.\")\n",
    "        f = open(f\"{self.config.root_dir}/{self.config.mlflow_input_example_path}\")\n",
    "        input_example = json.load(f)\n",
    "\n",
    "        # handle mlflow input example data\n",
    "        data_key = input_example[\"columns\"][0]\n",
    "        data_val = [i[0] for i in input_example['data']]\n",
    "\n",
    "        # request params\n",
    "        self.req_body_key = data_key\n",
    "        self.req_body = {\n",
    "            data_key: data_val\n",
    "        }\n",
    "        \n",
    "    def get_request_body_value(self) -> list:\n",
    "        \"\"\"get the request body data\n",
    "\n",
    "        Returns:\n",
    "            req_body: list type\n",
    "        \"\"\"\n",
    "        logger.info(\"Get MLflow input example value.\")\n",
    "        req_body_value = self.req_body[self.req_body_key]\n",
    "        return req_body_value\n",
    "    \n",
    "    def get_output_length(self):\n",
    "        \"\"\"get the output length of the predict result\n",
    "\n",
    "        Returns:\n",
    "            len_result: list type\n",
    "        \"\"\"\n",
    "        logger.info(\"Get predicted result length.\")\n",
    "        result = requests.post(\n",
    "            url = self.config.app_endpoint, \n",
    "            json = self.req_body\n",
    "        )\n",
    "        len_result = len(result.json())\n",
    "        return len_result\n",
    "\n",
    "    def is_output_type_list(self) -> bool:\n",
    "        \"\"\"check if the output file is list data type\n",
    "\n",
    "        Returns:\n",
    "            is_list: bool type\n",
    "        \"\"\"\n",
    "        logger.info(\"Check is the predicted output is list.\")\n",
    "        result = requests.post(\n",
    "            url=self.config.app_endpoint, \n",
    "            json=self.req_body\n",
    "        )\n",
    "        is_list = type(result.json()) is list\n",
    "        return is_list\n",
    "\n",
    "    def is_output_type_consistent(self) -> bool:\n",
    "        \"\"\"check if the output file have consistent\n",
    "        data type inside a list\n",
    "\n",
    "        Returns:\n",
    "            bool type\n",
    "        \"\"\"\n",
    "        logger.info(\"Check is each predicted output is integer\")\n",
    "        result = requests.post(\n",
    "            url=self.config.app_endpoint, \n",
    "            json=self.req_body\n",
    "        )\n",
    "        for result in result.json():\n",
    "            if type(result) is not int:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Testing\n",
    "\n",
    "**Debug**: Simulate the unit testing without library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-11 08:31:39,720: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-09-11 08:31:39,722: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2024-09-11 08:31:39,723: INFO: common: created directory at: artifacts]\n",
      "[2024-09-11 08:31:39,723: INFO: common: created directory at: artifacts/test]\n",
      "[2024-09-11 08:31:39,724: INFO: 999233882: Set MLflow Client.]\n",
      "[2024-09-11 08:31:39,733: INFO: 999233882: Get the deployed model run id.]\n",
      "[2024-09-11 08:31:39,733: INFO: 999233882: Downloading vectorizer from MLflow's artifacts.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 92.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-11 08:31:39,767: INFO: 999233882: Open MLflow input example.]\n",
      "Review Contents: \n",
      "[2024-09-11 08:31:39,768: INFO: 999233882: Get MLflow input example value.]\n",
      "brg mulus,kiriman jg cepat, thx\n",
      "Terima kasih Adata Store dan Lazada, barang sudah sampai, mantab\n",
      "Trimaksih Lazada barang nya sangat bagus dan memuas kan ..  Waktu pesen kemarin blm ada free besi ny .  Skrng udh ada .  Heee heee ..\n",
      "barang sampai juga agak lama pengirimanya,, Alhamdulillah barang gak ada yg cacat,,\n",
      "bagus, dapet bonus kabel strap lumayan ðŸ˜\n",
      "Mohon tulis harga dengan benar\n",
      "mantab jiwa,,sory barang ga sempat dipoto\n",
      "Recomended banget lur...\n",
      "Terima kasih Lazada pengiriman cepat dan packingnya rapi, barang sesuai dgn pesanan saya...tp belum saya coba aktifkan\n",
      "Saya kira karena liburan bakal lama sampainya, ternyata tidak,  Barang asli setelah dibuka,sama dengan foto   Thanks lazada, memang effortless banget\n",
      "\n",
      "Begin tests:\n",
      "[2024-09-11 08:31:39,768: INFO: 999233882: Get predicted result length.]\n",
      "[2024-09-11 08:31:39,938: INFO: 999233882: Get MLflow input example value.]\n",
      "Is same size: True\n",
      "[2024-09-11 08:31:39,939: INFO: 999233882: Check is the predicted output is list.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the output is list: True\n",
      "[2024-09-11 08:31:40,141: INFO: 999233882: Check is each predicted output is integer]\n",
      "Is the output consistent: True\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    unit_testing_config = config.get_unit_test_config()\n",
    "    unit_test = UnitTesting(config=unit_testing_config)\n",
    "    unit_test.set_request_body()\n",
    "    \n",
    "    print(\"Review Contents: \")\n",
    "    for content in unit_test.get_request_body_value():\n",
    "        print(content)\n",
    "    \n",
    "    print(\"\\nBegin tests:\")\n",
    "    print(f\"Is same size: {unit_test.get_output_length() == len(unit_test.get_request_body_value())}\")\n",
    "    print(f\"Is the output is list: {unit_test.is_output_type_list() == True}\")\n",
    "    print(f\"Is the output consistent: {unit_test.is_output_type_consistent() == True}\")\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lazada-id-reviews-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
