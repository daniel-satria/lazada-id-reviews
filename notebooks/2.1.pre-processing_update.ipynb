{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/learning/mlops/pacmann/lazada-id-reviews/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the main directory\n",
    "# So, it's executed from main directory\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/learning/mlops/pacmann/lazada-id-reviews'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing Config\n",
    "\n",
    "This code will be apply in `src/LadazaIDReview/entity/config_entity.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataDumpConfig:\n",
    "    root_dir: Path\n",
    "    reviews_path: Path\n",
    "    input_train_path: Path\n",
    "    input_test_path: Path\n",
    "    output_train_path: Path\n",
    "    output_test_path: Path\n",
    "    params_test_size: float\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataPreprocessingConfig:\n",
    "    root_dir: Path\n",
    "    input_train_path: Path\n",
    "    input_test_path: Path\n",
    "    vectorized_train_path: Path\n",
    "    vectorized_test_path: Path\n",
    "    model_dir: Path\n",
    "    vectorizer_model_path: Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing Config Manager\n",
    "\n",
    "This code will be apply in `src/LazadaIDReview/config/configurations.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LazadaIDReviews.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from LazadaIDReviews.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_filepath = CONFIG_FILE_PATH,\n",
    "                 params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_dump_data_config(self) -> DataDumpConfig:\n",
    "        \"\"\"read data dump config file and store as config entity\n",
    "        then apply the dataclasses\n",
    "        \n",
    "        Returns:\n",
    "            config: PreprocessingConfig type\n",
    "        \"\"\"\n",
    "        dump_config = self.config.dump_data\n",
    "        ingest_config = self.config.ingest_from_sql\n",
    "        dataset_params = self.params\n",
    "\n",
    "        create_directories([dump_config.root_dir])\n",
    "\n",
    "        config = DataDumpConfig(\n",
    "            root_dir=dump_config.root_dir,\n",
    "            reviews_path=ingest_config.reviews_path,\n",
    "            input_train_path=dump_config.input_train_path,\n",
    "            input_test_path=dump_config.input_test_path,\n",
    "            output_train_path=dump_config.output_train_path,\n",
    "            output_test_path=dump_config.output_test_path,\n",
    "            params_test_size=dataset_params.TEST_SIZE\n",
    "        )\n",
    "\n",
    "        return config\n",
    "    \n",
    "    def get_preprocessing_data_config(self) -> DataPreprocessingConfig:\n",
    "        \"\"\"read preprocessing config file and store as config entity\n",
    "        then apply the dataclasses\n",
    "        \n",
    "        Returns:\n",
    "            config: PreprocessingConfig type\n",
    "        \"\"\"\n",
    "        dump_config = self.config.dump_data\n",
    "        vectorize_config = self.config.vectorize_data\n",
    "        train_config = self.config.train_model\n",
    "\n",
    "        create_directories([vectorize_config.root_dir])\n",
    "\n",
    "        config = DataPreprocessingConfig(\n",
    "            root_dir=vectorize_config.root_dir,\n",
    "            input_train_path=Path(dump_config.input_train_path),\n",
    "            input_test_path=Path(dump_config.input_test_path),\n",
    "            vectorized_train_path=Path(vectorize_config.vectorized_train_path),\n",
    "            vectorized_test_path=Path(vectorize_config.vectorized_test_path),\n",
    "            model_dir=train_config.root_dir,\n",
    "            vectorizer_model_path=Path(vectorize_config.vectorizer_model_path)\n",
    "        )\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Preprocessing\n",
    "\n",
    "This code in `src/LazadaIDReview/components/preprocessing.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we would do?\n",
    "+ Drop null values\n",
    "+ Splitting the dataset to train and test data\n",
    "+ Vectorize text using `TFIDF`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated before; let‚Äôs load, select columns, and drop null values from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from LazadaIDReviews import logger\n",
    "\n",
    "class Preprocessing:\n",
    "    def __init__(self, config: DataDumpConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def dump_data(self) -> None:\n",
    "        \"\"\"dump the splited dataset to data training and testing\n",
    "        \"\"\"\n",
    "        logger.info(f\"Read reviews file.\")\n",
    "        dataset_reviews = pd.read_csv(self.config.reviews_path)\n",
    "        dataset = dataset_reviews[[\"rating\", \"reviewContent\"]].copy()\n",
    "        dataset.dropna(inplace=True)\n",
    "        \n",
    "        logger.info(f\"Split reviews file to data train and test.\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            dataset[\"reviewContent\"], \n",
    "            dataset[\"rating\"], \n",
    "            test_size=self.config.params_test_size\n",
    "        )\n",
    "        \n",
    "        # NOTE: improve the performance with ROS\n",
    "        logger.info(f\"Perform random over sampler.\")\n",
    "        ros = RandomOverSampler()\n",
    "        X_train_ros, y_train_ros = ros.fit_resample(pd.DataFrame(X_train), pd.DataFrame(y_train))\n",
    "        \n",
    "        # NOTE: data save as series\n",
    "        logger.info(f\"Dump data train into {self.config.root_dir} directory.\")\n",
    "        X_train_ros[\"reviewContent\"].to_pickle(self.config.input_train_path)\n",
    "        X_test.to_pickle(self.config.input_test_path)\n",
    "        \n",
    "        # NOTE: data save as series\n",
    "        logger.info(f\"Dump data test into {self.config.root_dir} directory.\")\n",
    "        y_train_ros[\"rating\"].to_pickle(self.config.output_train_path)\n",
    "        y_test.to_pickle(self.config.output_test_path)\n",
    "        \n",
    "    def vectorize_data(self) -> None:\n",
    "        \"\"\"vectorize the splited dataset and dump vectorizer model\n",
    "        \"\"\"\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        \n",
    "        logger.info(f\"Load data train in {self.config.input_train_path}.\")\n",
    "        X_train = joblib.load(self.config.input_train_path)\n",
    "        \n",
    "        logger.info(f\"Load data test in {self.config.input_test_path}.\")\n",
    "        X_test = joblib.load(self.config.input_test_path)\n",
    "        \n",
    "        logger.info(f\"Vectorize the data.\")\n",
    "        X_train_vec = vectorizer.fit_transform(X_train)\n",
    "        X_test_vec = vectorizer.transform(X_test)\n",
    "        \n",
    "        logger.info(f\"Dump the vectorized data.\")\n",
    "        joblib.dump(X_train_vec, self.config.vectorized_train_path)\n",
    "        joblib.dump(X_test_vec, self.config.vectorized_test_path)\n",
    "        \n",
    "        logger.info(f\"Creating {self.config.model_dir} directory.\")\n",
    "        model_dir = str(self.config.model_dir)\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        logger.info(f\"Save the vectorizer model.\")\n",
    "        joblib.dump(vectorizer, self.config.vectorizer_model_path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump the Data Train and Data Test\n",
    "\n",
    "This code in `src/LazadaIDReview/pipeline/step_02_preprocessing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-11 04:31:46,469: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-09-11 04:31:46,479: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2024-09-11 04:31:46,481: INFO: common: created directory at: artifacts]\n",
      "[2024-09-11 04:31:46,482: INFO: common: created directory at: artifacts/data]\n",
      "[2024-09-11 04:31:46,484: INFO: 2608593555: Read reviews file.]\n",
      "[2024-09-11 04:31:47,187: INFO: 2608593555: Split reviews file to data train and test.]\n",
      "[2024-09-11 04:31:47,195: INFO: 2608593555: Perform random over sampler.]\n",
      "[2024-09-11 04:31:47,207: INFO: 2608593555: Dump data train into artifacts/data directory.]\n",
      "[2024-09-11 04:31:47,254: INFO: 2608593555: Dump data test into artifacts/data directory.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    dump_data_config = config.get_dump_data_config()\n",
    "    data_ingestion = Preprocessing(config=dump_data_config)\n",
    "    data_ingestion.dump_data()\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debug**: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Barangnya baru sampai, baru pertama kali di ke...\n",
       "1                    Tv nya jossss, 3 hari nyampe cikarang\n",
       "2               Barang nya bagus gan..mantap lah pokok nya\n",
       "3        Produk telah tiba sesuai estimasi.. pelayanan ...\n",
       "4                                                    bagus\n",
       "                               ...                        \n",
       "82950             Mau kredit. Cicilan nya berapa x bayar ?\n",
       "82951    eliminasi 2 hari packing rapi tapi warna gak s...\n",
       "82952    TV nya sdh sampe dan bagus... cuma lama banget...\n",
       "82953    bagus hanya saja saat disatukan layar dengan k...\n",
       "82954    puas bgt kalo untuk tv ini, harga murah...kual...\n",
       "Name: reviewContent, Length: 82955, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = joblib.load(dump_data_config.input_train_path)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        5\n",
       "2        5\n",
       "3        5\n",
       "4        5\n",
       "        ..\n",
       "82950    4\n",
       "82951    4\n",
       "82952    4\n",
       "82953    4\n",
       "82954    4\n",
       "Name: rating, Length: 82955, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = joblib.load(dump_data_config.output_train_path)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4101              Terimakasih barang udah sampe dan sesuai.\n",
       "139337    makasih banget buat Nadira Store dn lazada.psa...\n",
       "201703    Bagus, sesuai dengan pesanan... Sangat puas pe...\n",
       "30999     Produknya bagus, sesuai dengan apa yang di des...\n",
       "93353                                        Sesuai pesanan\n",
       "                                ...                        \n",
       "172426                                   mantap dah... imut\n",
       "110691    Barang yang dikirim sesuai dengan deskripsi, p...\n",
       "45451     produk nya bagus .. cm pas pengiriman nya tanp...\n",
       "83813                                                üëèüèªüëèüèªüëèüèª\n",
       "145913                                        Mantul betttt\n",
       "Name: reviewContent, Length: 85624, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = joblib.load(dump_data_config.input_test_path)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4101      4\n",
       "139337    5\n",
       "201703    5\n",
       "30999     5\n",
       "93353     5\n",
       "         ..\n",
       "172426    5\n",
       "110691    5\n",
       "45451     5\n",
       "83813     5\n",
       "145913    5\n",
       "Name: rating, Length: 85624, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = joblib.load(dump_data_config.output_test_path)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the Data Train and Data Test\n",
    "\n",
    "This code in `src/LazadaIDReview/pipeline/step_02_preprocessing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-11 04:32:10,322: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-09-11 04:32:10,324: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2024-09-11 04:32:10,325: INFO: common: created directory at: artifacts]\n",
      "[2024-09-11 04:32:10,326: INFO: common: created directory at: artifacts/preprocessing]\n",
      "[2024-09-11 04:32:10,327: INFO: 2608593555: Load data train in artifacts/data/X_train.pkl.]\n",
      "[2024-09-11 04:32:10,404: INFO: 2608593555: Load data test in artifacts/data/X_test.pkl.]\n",
      "[2024-09-11 04:32:10,527: INFO: 2608593555: Vectorize the data.]\n",
      "[2024-09-11 04:32:12,311: INFO: 2608593555: Dump the vectorized data.]\n",
      "[2024-09-11 04:32:12,399: INFO: 2608593555: Creating artifacts/models directory.]\n",
      "[2024-09-11 04:32:12,399: INFO: 2608593555: Save the vectorizer model.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    preprocessing_config = config.get_preprocessing_data_config()\n",
    "    preprocessing = Preprocessing(config=preprocessing_config)\n",
    "    preprocessing.vectorize_data()\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debug**: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<82955x13588 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1224387 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec = joblib.load(preprocessing_config.vectorized_train_path)\n",
    "X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<85624x13588 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 981246 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec = joblib.load(preprocessing_config.vectorized_test_path)\n",
    "X_test_vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_lzd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
